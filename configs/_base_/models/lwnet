# model settings
norm_cfg = dict(type='BN', requires_grad=True)
data_preprocessor = dict(
    type='SegDataPreProcessor',
    mean=[123.675, 116.28, 103.53],
    std=[58.395, 57.12, 57.375],
    bgr_to_rgb=True,
    pad_val=0,
    seg_pad_val=255)
model = dict(
    type='EncoderDecoder',
    data_preprocessor=data_preprocessor,
    backbone=dict(
        type='LWNet',
        cfgs=[
            [3, 1, 16, 1],
            [3, 3, 24, 2],
            [3, 3, 24, 1],
            [5, 3, 48, 2],
            [5, 3, 48, 1],
            [3, 4, 96, 2],
            [3, 4, 96, 1],
            [5, 6, 128, 2],
            [5, 6, 128, 1],
            [3, 6, 128, 1],
        ],
        channels=[24, 48, 96, 128],
        out_channels=[None, 160, 160, 160],
        embed_out_indice=[2, 4, 6, 9],
        decode_out_indices=[1, 2, 3],
        num_blocks=2,
        depths=4,
        key_dim=16,
        num_heads=8,
        attn_ratios=2,
        c2t_stride=2,
        reduction_ratio=4,
        expansion_ratio=2,
        drop_path_rate=0.1,
        norm_cfg=norm_cfg,
        wavelet_name='db1',
        decomposition_level=3,
        use_dwt=True,
    ),
    decode_head=dict(
        type='LWNet_Head',
        in_channels=[160, 160, 160],
        in_index=[0, 1, 2],
        channels=160,
        dropout_ratio=0.1,
        num_classes=6,  # vaihingen 6  loveda 7
        norm_cfg=norm_cfg,
        align_corners=False,
        loss_decode=[
            dict(type='CrossEntropyLoss', loss_name='loss_ce', loss_weight=1.0),
            dict(type='DiceLoss', loss_name='loss_dice', loss_weight=3.0)]),
    # Training settings
    train_cfg=dict(),
    test_cfg=dict(mode='whole'))
